# LLM + RAG â€“ Code de lâ€™Ã©ducation

---

## ðŸ‡«ðŸ‡· Partie 1 â€” Description du projet (FranÃ§ais)

### Objectif
Ce projet vise Ã  concevoir un **assistant IA local basÃ© sur un pipeline RAG (Retrieval-Augmented Generation)** appliquÃ© au **Code de lâ€™Ã©ducation franÃ§ais**.  
Lâ€™objectif est de fournir des rÃ©ponses **fiables, traÃ§ables et vÃ©rifiables**, fondÃ©es exclusivement sur les articles du Code de lâ€™Ã©ducation, **sans hallucination du modÃ¨le**.

Une **mise Ã  disposition gratuite** sous forme dâ€™application est envisagÃ©e Ã  terme, notamment Ã  destination des **chefs dâ€™Ã©tablissement dâ€™EPLE**, via une plateforme comme **Hugging Face**.

---

## Architecture du projet

```
llm_code_education/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ code_education.pdf
â”‚   â”œâ”€â”€ chunks_articles.jsonl
â”‚   â”œâ”€â”€ chunks_preview.md
â”‚   â””â”€â”€ chunks_audit.md
â”‚
â”œâ”€â”€ db/
â”‚   â””â”€â”€ faiss_code_edu_by_article/
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ mistral.gguf
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ chunk_by_article.py
â”‚   â”œâ”€â”€ build_faiss_index.py
â”‚   â”œâ”€â”€ rag_chat_ollama.py
â”‚   â””â”€â”€ rag_chat_llama.py
â”‚
â”œâ”€â”€ llm_code_education_env/
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## Description des dossiers

### `data/`
Contient lâ€™ensemble des **donnÃ©es sources et intermÃ©diaires** :
- `code_education.pdf` : source officielle du Code de lâ€™Ã©ducation.
- `chunks_articles.jsonl` : base principale des articles (1 chunk = 1 article).
- `chunks_preview.md` : aperÃ§u lisible des articles dÃ©coupÃ©s.
- `chunks_audit.md` : rapport de contrÃ´le qualitÃ©.

### `db/`
Contient lâ€™index vectoriel :
- `faiss_code_edu_by_article/` : index FAISS construit Ã  partir des articles du Code de lâ€™Ã©ducation.

### `models/`
- `mistral.gguf` : modÃ¨le **Mistral Instruct** quantifiÃ© au format **GGUF**, utilisÃ© via `llama.cpp` pour assurer la compatibilitÃ© avec un dÃ©ploiement Hugging Face.

### `src/`
Contient le **code applicatif principal** :
- `chunk_by_article.py`  
  â†’ Extraction du PDF et dÃ©coupage **article par article**, avec nettoyage des en-tÃªtes/pieds de page.
- `build_faiss_index.py`  
  â†’ CrÃ©ation des embeddings et construction de lâ€™index FAISS.
- `rag_chat_ollama.py`  
  â†’ Version initiale du chatbot RAG utilisant **Ollama + Mistral** pour les tests locaux.
- `rag_chat_llama.py`  
  â†’ Version adaptÃ©e pour le dÃ©ploiement :
    - remplacement dâ€™Ollama par **`llama.cpp`**,
    - utilisation dâ€™un modÃ¨le **Mistral GGUF**,
    - paramÃ¨tres optimisÃ©s (contexte, batch, nombre dâ€™articles),
    - compatibilitÃ© **Hugging Face Spaces**.

---

## PrÃ©paration au dÃ©ploiement sur Hugging Face

Les Ã©tapes suivantes ont Ã©tÃ© rÃ©alisÃ©es :
- crÃ©ation dâ€™une version dÃ©diÃ©e `rag_chat_llama.py`,
- abandon dâ€™Ollama au profit de **`llama.cpp`**, compatible Hugging Face,
- tÃ©lÃ©chargement et intÃ©gration dâ€™un **modÃ¨le Mistral GGUF**,
- rÃ©duction et optimisation du contexte pour de meilleures performances CPU,
- prÃ©paration Ã  une interface web lÃ©gÃ¨re (Gradio / FastAPI).

---

## ðŸ‡¬ðŸ‡§ Part 2 â€” Project description (English)

### Goal
This project aims to build a **local RAG-based AI assistant** applied to the **French Code of Education**.

The objective is to provide **reliable, source-grounded answers**, strictly based on legal articles, with **verbatim citations** and strong hallucination prevention.

A **free public deployment** is planned, especially for **school principals**, via **Hugging Face Spaces**.

---

## Hugging Face deployment preparation
- Creation of a dedicated `rag_chat_llama.py` version
- Replacement of Ollama with `llama.cpp`
- Download and integration of a quantized Mistral GGUF model
- Context size and retrieval strategy optimized for CPU usage

---

## Disclaimer
This is an **experimental project**.  
Generated answers are **not legal advice** and must always be verified against official legal sources.
